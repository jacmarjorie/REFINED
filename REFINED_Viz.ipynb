{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prepare expression data from TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print 10 best features:\n",
      "                     Specs         Score\n",
      "48631   ENSG00000262902.1  2.486474e+09\n",
      "5496   ENSG00000124233.11  1.778296e+09\n",
      "35533   ENSG00000237973.1  1.412967e+09\n",
      "21558   ENSG00000210082.2  8.031701e+08\n",
      "5465    ENSG00000124157.6  4.735443e+08\n",
      "19433   ENSG00000202198.1  4.664365e+08\n",
      "27198   ENSG00000225972.1  4.464057e+08\n",
      "48938   ENSG00000263639.4  4.292310e+08\n",
      "21594   ENSG00000211459.2  3.270682e+08\n",
      "17968   ENSG00000198886.2  3.180589e+08\n",
      "print 10 best features:\n",
      "                     Specs         Score\n",
      "5496   ENSG00000124233.11  1.601779e+09\n",
      "48938   ENSG00000263639.4  1.141518e+09\n",
      "19433   ENSG00000202198.1  6.762889e+08\n",
      "5465    ENSG00000124157.6  4.421978e+08\n",
      "21594   ENSG00000211459.2  4.186632e+08\n",
      "2051   ENSG00000096006.10  3.328794e+08\n",
      "8446   ENSG00000143632.13  2.990593e+08\n",
      "48631   ENSG00000262902.1  2.658394e+08\n",
      "13348   ENSG00000172551.9  2.640845e+08\n",
      "29500   ENSG00000229314.5  2.442860e+08\n",
      "print 10 best features:\n",
      "                     Specs         Score\n",
      "19433   ENSG00000202198.1  3.608474e+09\n",
      "48631   ENSG00000262902.1  2.514031e+09\n",
      "21594   ENSG00000211459.2  1.844743e+09\n",
      "35533   ENSG00000237973.1  1.397182e+09\n",
      "27198   ENSG00000225972.1  1.360372e+09\n",
      "21558   ENSG00000210082.2  1.026426e+09\n",
      "5496   ENSG00000124233.11  8.164411e+08\n",
      "18000   ENSG00000198938.2  6.438067e+08\n",
      "48938   ENSG00000263639.4  5.967864e+08\n",
      "17968   ENSG00000198886.2  5.864804e+08\n",
      "1608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def addFile(file): \n",
    "\tdf = pd.read_csv(file, sep = \"\\t\")\n",
    "\tname = os.path.basename(file)\n",
    "\tdf['file_name'] = name\n",
    "\tdf.columns = ['gene', 'fpkm', 'file_name']\n",
    "\treturn(df)\n",
    "\n",
    "def loadExpression(filepath):\n",
    "\tfiles = glob.glob(filepath)     \n",
    "\tdfs = (addFile(f) for f in files)\n",
    "\treturn pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def adjust(x): \n",
    "\treturn x+.0001\n",
    "\n",
    "\n",
    "def topKFeatures(X, y, ifPlot = False, topK = 500):\n",
    "\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k = topK)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    print(\"print 10 best features:\\n\", featureScores.nlargest(10,'Score'))\n",
    "    \n",
    "    if ifPlot == True:\n",
    "        plt.figure()\n",
    "        featureScores.nlargest(10,'Score').plot(kind='barh')\n",
    "        plt.show()\n",
    "    \n",
    "    topk_features = featureScores.nlargest(topK,'Score').Specs.values\n",
    "\n",
    "    return topk_features\n",
    "\n",
    "clinical = pd.read_csv(\"/nfs/home/jaclyns/tcga/nationwidechildrens.org_clinical_patient_prad.txt\", sep=\"\\t\")\n",
    "# print(labels)\n",
    "\n",
    "mapping = pd.read_csv(\"/nfs/home/jaclyns/tcga/prad.txt\", sep=\"\\t\")\n",
    "mapping.columns = [\"case_id\", \"aliquot_id\", \"file_name\"]\n",
    "# print(mapping)\n",
    "\n",
    "expression = loadExpression(\"/nfs/home/jaclyns/tcga/prad/*FPKM-UQ.txt\")\n",
    "# print(expression)\n",
    "\n",
    "labels = clinical[['bcr_patient_uuid', 'gleason_pattern_primary', 'gleason_pattern_secondary', 'gleason_score']].merge(mapping, right_on='case_id', left_on='bcr_patient_uuid')\n",
    "labels = labels[['aliquot_id', 'gleason_pattern_primary', 'gleason_pattern_secondary', 'gleason_score']]\n",
    "\n",
    "expression = expression.merge(mapping, right_on='file_name', left_on='file_name')\n",
    "expression = expression.dropna(subset=['aliquot_id'])\n",
    "matrix = expression.pivot(index = 'aliquot_id', columns = 'gene', values = 'fpkm')\n",
    "fmatrix = matrix.join(labels.set_index('aliquot_id'), on='aliquot_id')\n",
    "\n",
    "preX = fmatrix.drop('gleason_score', 1)\n",
    "prey0 = fmatrix[['gleason_pattern_primary']] \n",
    "prey1 = fmatrix[['gleason_pattern_secondary']]\n",
    "prey2 = fmatrix[['gleason_score']]\n",
    "\n",
    "topfs0 = set(topKFeatures(preX,prey0, topK=1000).tolist())\n",
    "topfs1 = set(topKFeatures(preX,prey1, topK=1000).tolist())\n",
    "topfs2 = set(topKFeatures(preX,prey2, topK=1000).tolist())\n",
    "\n",
    "inter = topfs0.union(topfs1, topfs2)\n",
    "print(len(inter))\n",
    "# topfs = topfs0 + topfs1 + topfs2\n",
    "# topfs = set(topfs)\n",
    "# print(len(topfs))\n",
    "features = preX[inter]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with REFINED\n",
    "\n",
    "In this notebook we show how to convert tabular data into images, and show those images for visualization. As it is explained in the main markdown, REFINED has two steps: Initialization with manifold learning techniques (MDS), and optimization with a search technique (hill climbing). Therefore to perform visualization with REFINED, we need to do the two steps and once we get the coordinate in the square image for each feature of the tabular data we can generate images associate with each datapoint (sample).\n",
    "\n",
    "### 1. In the below cell we perform initialization with MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> MDS\n",
      ">>>> Data  is loaded\n",
      ">>>> MDS dimensionality reduction is done\n",
      ">> Assign features to pixels: 762 / 1608\n",
      ">> Assign features to pixels: 951 / 1608\n",
      ">> Assign features to pixels: 1028 / 1608\n",
      ">> Assign features to pixels: 1094 / 1608\n",
      ">> Assign features to pixels: 1140 / 1608\n",
      ">> Assign features to pixels: 1182 / 1608\n",
      ">> Assign features to pixels: 1218 / 1608\n",
      ">> Assign features to pixels: 1254 / 1608\n",
      ">> Assign features to pixels: 1282 / 1608\n",
      ">> Assign features to pixels: 1310 / 1608\n",
      ">> Assign features to pixels: 1333 / 1608\n",
      ">> Assign features to pixels: 1357 / 1608\n",
      ">> Assign features to pixels: 1379 / 1608\n",
      ">> Assign features to pixels: 1407 / 1608\n",
      ">> Assign features to pixels: 1423 / 1608\n",
      ">> Assign features to pixels: 1439 / 1608\n",
      ">> Assign features to pixels: 1452 / 1608\n",
      ">> Assign features to pixels: 1462 / 1608\n",
      ">> Assign features to pixels: 1473 / 1608\n",
      ">> Assign features to pixels: 1480 / 1608\n",
      ">> Assign features to pixels: 1486 / 1608\n",
      ">> Assign features to pixels: 1494 / 1608\n",
      ">> Assign features to pixels: 1502 / 1608\n",
      ">> Assign features to pixels: 1509 / 1608\n",
      ">> Assign features to pixels: 1516 / 1608\n",
      ">> Assign features to pixels: 1521 / 1608\n",
      ">> Assign features to pixels: 1527 / 1608\n",
      ">> Assign features to pixels: 1535 / 1608\n",
      ">> Assign features to pixels: 1542 / 1608\n",
      ">> Assign features to pixels: 1552 / 1608\n",
      ">> Assign features to pixels: 1557 / 1608\n",
      ">> Assign features to pixels: 1562 / 1608\n",
      ">> Assign features to pixels: 1568 / 1608\n",
      ">> Assign features to pixels: 1573 / 1608\n",
      ">> Assign features to pixels: 1577 / 1608\n",
      ">> Assign features to pixels: 1580 / 1608\n",
      ">> Assign features to pixels: 1584 / 1608\n",
      ">> Assign features to pixels: 1587 / 1608\n",
      ">> Assign features to pixels: 1590 / 1608\n",
      ">> Assign features to pixels: 1593 / 1608\n",
      ">> Assign features to pixels: 1596 / 1608\n",
      ">> Assign features to pixels: 1598 / 1608\n",
      ">> Assign features to pixels: 1599 / 1608\n",
      ">> Assign features to pixels: 1600 / 1608\n",
      ">> Assign features to pixels: 1601 / 1608\n",
      ">> Assign features to pixels: 1602 / 1608\n",
      ">> Assign features to pixels: 1603 / 1608\n",
      ">> Assign features to pixels: 1605 / 1608\n",
      ">> Assign features to pixels: 1606 / 1608\n",
      ">> Assign features to pixels: 1607 / 1608\n",
      ">> Assign features to pixels: 1608 / 1608\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import Toolbox\n",
    "from Toolbox import two_d_eq, Assign_features_to_pixels\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "import os\n",
    "os.chdir('/nfs/home/jaclyns/REFINED/data')\n",
    "#%% Loading the data\n",
    "# empty rows I manually removed from this file\n",
    "# Feat_DF = pd.read_csv(\"normalized_padel_feats_NCI60_672_small.csv\")\n",
    "#Feat_DF = pd.read_csv(\"C:\\\\Users\\\\obazgir\\\\Desktop\\\\CMDS_IMAGES_NEW\\\\normalized_padel_feats_NCI60_672.csv\")\n",
    "Feat_DF = features#.head(10)\n",
    "\n",
    "X = Feat_DF.values; #X = X[:,2:]\n",
    "original_input = pd.DataFrame(data = X)                              # The MDS input should be in a dataframe format with rows as samples and columns as features\n",
    "feature_names_list = original_input.columns.tolist()                 # Extracting feature_names_list (gene_names or descriptor_names)\n",
    "print(\">>>> Data  is loaded\")\n",
    "\n",
    "#%% MDS\n",
    "nn = math.ceil(np.sqrt(len(feature_names_list))) \t\t\t\t     # Image dimension\n",
    "Nn = original_input.shape[1] \t\t\t\t\t\t\t\t\t\t # Number of features\n",
    "    \n",
    "transposed_input = original_input.T \t\t\t\t\t\t\t     # The MDS input data must be transposed , because we want summarize each feature by two values (as compard to regular dimensionality reduction each sample will be described by two values)\n",
    "Euc_Dist = euclidean_distances(transposed_input) \t\t\t\t\t # Euclidean distance\n",
    "Euc_Dist = np.maximum(Euc_Dist, Euc_Dist.transpose())   \t\t\t # Making the Euclidean distance matrix symmetric\n",
    "\n",
    "embedding = MDS(n_components=2)\t\t\t\t\t\t\t\t\t\t # Reduce the dimensionality by MDS into 2 components\n",
    "mds_xy = embedding.fit_transform(transposed_input)\t\t\t\t\t # Apply MDS\t\t\t\n",
    "\n",
    "print(\">>>> MDS dimensionality reduction is done\")\n",
    "\n",
    "eq_xy = two_d_eq(mds_xy,Nn)\n",
    "Img = Assign_features_to_pixels(eq_xy,nn,verbose=1)\t\t\t\t\t# Img is the none-overlapping coordinates generated by MDS\n",
    "\n",
    "#%% To be saved for hill climbing\n",
    "Desc = Feat_DF.columns.tolist();  #Desc = Desc[2:]\t\t\t\t\t# Drug descriptors name\n",
    "Dist = pd.DataFrame(data = Euc_Dist, columns = Desc, index = Desc)\t# Generating a distance matrix which includes the Euclidean distance between each and every descriptor\n",
    "data = (Desc, Dist, Img\t)  \t\t\t\t\t\t\t\t\t\t\t# Preparing the hill climbing inputs\n",
    "\n",
    "# picklename = \"Init_MDS_Euc.pickle\"\n",
    "picklename = \"Init_PRAD_FPKM_3labels.pickle\"\n",
    "with open(picklename, 'wb') as f:\t\t\t\t\t# The hill climbing input is a pickle, therefore everything is saved as a pickle to be loaded by the hill climbing\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hill Climbing\n",
    "Once the initializaiton is performed, then we have to apply the search optimizaition (hill climbing). The below bash script will run the search optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun -np 32 python3 /nfs/home/jaclyns/REFINED/mpiHill_UF.py --init '/nfs/home/jaclyns/REFINED/data/Init_PRAD_FPKM_3labels.pickle'   --mapping 'Mapping_REFINED_3labels.pickle'  --evolution \"REFINED_Evolve_3labels.csv\" --num 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization\n",
    "Once the search optimization is performed and the coordinates for features are obtained, we can use the coordinates to generate images for visualization purpose or training CNNs. In the below code visualization is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualizing REFFINED images\n",
    "import math\n",
    "import pickle\n",
    "from Toolbox import REFINED_Im_Gen\n",
    "# MDS\n",
    "with open('/nfs/home/jaclyns/glow/Mapping_REFINED.pickle','rb') as file:\n",
    "    gene_names_MDS,coords_MDS,map_in_int_MDS = pickle.load(file)\n",
    "\n",
    "# # We pick the first 100 data points because of computational costs, but you can pick the entire datasets.\n",
    "# # X_REFINED_MDS = REFINED_Im_Gen(X[:100,:],nn, map_in_int_MDS, gene_names_MDS,coords_MDS)\n",
    "X_REFINED_MDS = REFINED_Im_Gen(X,nn, map_in_int_MDS, gene_names_MDS,coords_MDS)\n",
    "\n",
    "# Font = 20\n",
    "samples = Feat_DF.index\n",
    "\n",
    "# aliquot = samples[1]\n",
    "# print(aliquot)\n",
    "# X_REFINED_MDS[0,:]\n",
    "\n",
    "# fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "# plt.imshow(X_REFINED_MDS[1,:].reshape(nn,nn), cmap = 'gray') # cmap = 'viridis')\n",
    "# plt.axis('off')\n",
    "# plt.savefig('/nfs/home/jaclyns/tcga/'+samples[1]+'.png')\n",
    "# plt.close(fig)\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "    plt.imshow(X_REFINED_MDS[i,:].reshape(nn,nn), cmap = 'gray') #cmap = 'viridis')\n",
    "#     plt.title(\"Example1\", fontsize = Font)\n",
    "    plt.axis('off')\n",
    "    fig.savefig('/nfs/home/jaclyns/tcga/refined_images/'+samples[i]+'.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "# plt.subplot(142)\n",
    "# plt.imshow(X_REFINED_MDS[2,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example2\", fontsize = Font)\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(143)\n",
    "# plt.imshow(X_REFINED_MDS[3,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example3\", fontsize = Font)\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# plt.subplot(144)\n",
    "# plt.imshow(X_REFINED_MDS[4,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example4\", fontsize = Font)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to 16bit png\n",
    "Required for Clara Train classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4, 5}\n",
      "{3, 4, 5}\n",
      "{6, 7, 8, 9, 10}\n",
      "{2: 2, 3: 49, 4: 49, 5: 1}\n",
      "{3: 40, 4: 53, 5: 8}\n",
      "{6: 11, 7: 71, 8: 11, 9: 7, 10: 1}\n",
      "35\n",
      "16\n",
      "35\n",
      "15\n",
      "{\n",
      "  \"label_format\": [\n",
      "    1\n",
      "  ],\n",
      "  \"data_format\": \"channels_last\",\n",
      "  \"training\": [\n",
      "    {\n",
      "      \"image\": \"train_primary/011453b6-9736-4ea4-8845-bbe4416783d3.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/0c4495e4-b826-45ee-9ad3-873266b4585b.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/0cc5f629-5046-4d05-8a5f-923ce5c04b9e.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/104e14d3-f1d5-443f-88fd-6d67c98b1eff.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/12e19460-da9a-4ff4-8664-801e7f8829b7.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/14830a14-5495-4425-b6ef-78ccffafe03c.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/1c809dd1-f790-458d-9722-c3262afcd416.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/23e9edc6-a5ab-4dca-9243-a40e69d65615.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/26c39f49-cf54-41d6-8c46-c089f4a57002.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/26cd2872-7067-4cd7-bf85-4f028d9a819d.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/28ebf50e-d63f-439e-8e16-4a815eccb465.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/30e19950-9bbe-4952-8308-41689e57430c.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/36973833-7245-444f-94e9-062e6b83df14.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/3b524c3b-40b6-43bd-8108-5243463ce4a0.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/3b6f54f6-1812-474f-aced-f6790e59611c.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/3c3a7016-6270-4c87-af7d-53b46f7f8fd1.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/40eb0b4a-3863-403f-a90b-919bfa24237e.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/47d13480-7771-450a-ab70-07c8ca2eb14f.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/47faa91b-1bfa-4283-bc9d-dfa958252d6f.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/488dc8bd-9e74-48b2-a407-914f6e0ba0b6.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/4a54f172-9435-4e46-8396-405634425db2.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/51d276c8-e669-48c9-92d8-676a348249d5.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/59a3d245-6921-4799-9eb7-1bff6021680f.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/5b2c7f9e-d8f2-44db-8981-5acefbfd38c8.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/5c6bca7d-7dcc-4908-add3-c56606b313a7.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/743ad0e2-903e-4438-a575-1f06c286c079.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/776e6a2e-e939-4c92-b8dc-000c91bf5f64.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/783062c7-cf22-426d-8cd1-52ecdd28b43d.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/78808f76-820b-439f-8223-38f2899cad5f.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/7e9f1df1-e76f-45a0-9f1b-9a0cbd626430.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/801b06ab-6ef3-46ba-af12-3b2230aabf51.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/8c9b95d4-ee46-4312-ba8c-8000c9988ee8.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/8f097693-4c17-42f4-b319-dd3b4ae93005.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/951adcbd-7d7a-466c-bbac-7c7afb8b9df6.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/9675123f-6606-4e75-be55-3ef938c72178.png\",\n",
      "      \"label\": 0\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/07b4fdf4-19af-42f6-8c17-520047dce246.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/0cb961d7-87be-40c2-b703-3e424b8c8e78.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/0d9fb905-5374-4054-b799-9c4c4efd36d6.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/139abcca-ef3c-4520-9829-ebf4915d6b92.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/15602b9c-e496-4b8b-a416-82db780d8f28.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/1eda4d9f-e9a1-4ee7-8c71-559c8940b751.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/2031e5cb-18c3-421e-b8af-d5dab73e3a89.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/27357b4d-5d44-4c5e-bb80-0d5f68c3db8e.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/285a1a43-5494-49f4-95bb-671ebc1a953a.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/2bd35c12-2701-45c4-a6ea-981667028597.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/2c178e64-b87b-4887-b599-cc928e45db86.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/2cb1479d-b88e-42a6-a576-e519c98689ca.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/30861ba6-6539-47a5-82df-5f89d8101d05.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/3790dc43-aa3d-4d1b-aa7a-340675c98bd4.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/416bc8ff-9dd9-4b0c-b0f7-66cb8a437aad.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/487c555b-81bb-4b70-8219-9abac8394b9f.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/4979a47e-0078-40c7-abad-849dfd54263c.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/4be2bce2-2032-41a4-af3a-5f01a698e143.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/51cd07b8-f680-4bc2-a207-d0317f5f9358.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/5bd95b46-d04b-49a9-964a-dd49570f4960.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/5e185249-6ea1-460b-b841-f40e94ea1ccd.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/5f4f5adc-cebd-473a-94c7-b93426be2b95.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/6551bbb1-297f-41db-969b-17bb3c432426.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/6a2c4d22-f7b6-4e0a-bd71-a669786da5b1.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/6eb0d270-797d-49ab-9bda-a5f0a70a6695.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/7aa49ecf-9e25-4166-9ed2-487c41f1066c.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/7afedcd4-d921-4996-9587-a8faa03dcea0.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/7e787a16-e77d-46eb-8666-7489349b5c82.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/81388e39-1fc8-47bd-b49b-946bc979996d.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/85e48131-0ef8-4b94-986a-3829ccad6d25.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/8a2f149d-34a9-4be2-8bc5-d3d25f1df7e3.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/8d91b55d-0a51-44d3-bcc7-d6d95027683a.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/938046b4-330f-49e1-99b3-4cc4a1a1e48d.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/9584ae14-c30b-421b-8975-b5b1bb94a465.png\",\n",
      "      \"label\": 1\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"train_primary/9caa440e-a8a6-4851-b62e-4ebb09412fad.png\",\n",
      "      \"label\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "labels0 = prey0['gleason_pattern_primary'].tolist()\n",
    "labels1 = prey1['gleason_pattern_secondary'].tolist()\n",
    "labels2 = prey2['gleason_score'].tolist()\n",
    "\n",
    "dls = set(labels0)\n",
    "print(dls)\n",
    "dls1 = set(labels1)\n",
    "print(dls1)\n",
    "dls2 = set(labels2)\n",
    "print(dls2)\n",
    "\n",
    "samples = features.index\n",
    "\n",
    "labelMap0 = {2: 0, 3: 1, 4: 2, 5: 3}\n",
    "labelMap1 = {3: 0, 4: 1, 5: 2}\n",
    "labelMap2 = {6: 0, 7: 1, 8: 2, 9: 3, 10: 4}\n",
    "\n",
    "labelDist0 = {2: 0, 3: 0, 4: 0, 5: 0}\n",
    "labelDist1 = {3: 0, 4: 0, 5: 0}\n",
    "labelDist2 = {6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n",
    "\n",
    "for s in range(len(samples)):\n",
    "    labelDist0[labels0[s]] += 1\n",
    "    labelDist1[labels1[s]] += 1\n",
    "    labelDist2[labels2[s]] += 1\n",
    "\n",
    "print(labelDist0)\n",
    "print(labelDist1)\n",
    "print(labelDist2)\n",
    "\n",
    "\n",
    "\n",
    "## we can do binary classification with 2/3 = 0 and 4/5 = 1\n",
    "## we can split 70/30 training and testing\n",
    "labels = {}\n",
    "labelMap = {2: 0, 3: 0, 4: 1, 5: 1}\n",
    "for s in range(len(samples)):\n",
    "    labels[samples[s]] = labelMap[labels0[s]]\n",
    "\n",
    "zeros = [k for k, v in labels.items() if v == 0]\n",
    "ones = [k for k, v in labels.items() if v == 1]\n",
    "\n",
    "trainingZeros = zeros[:35]\n",
    "testingZeros = zeros[35:]\n",
    "trainingOnes = ones[:35]\n",
    "testingOnes = ones[35:]\n",
    "\n",
    "# print(trainingZeros)\n",
    "print(len(trainingZeros))\n",
    "# print(trainingZeros)\n",
    "print(len(testingZeros))\n",
    "\n",
    "# print(trainingOnes)\n",
    "print(len(trainingOnes))\n",
    "# print(testingOnes)\n",
    "print(len(testingOnes))\n",
    "\n",
    "training = []\n",
    "path = \"train_primary\"\n",
    "dataset = \"/nfs/home/jaclyns/tcga/dataset_primary.json\"\n",
    "for s in trainingZeros + trainingOnes:\n",
    "    iname = path+\"/\"+s+\".png\"\n",
    "    training.append({ \"image\": iname, \"label\": labels[s] })\n",
    "    \n",
    "init_json = { \"label_format\": [1], \"data_format\": \"channels_last\", \"training\": training }\n",
    "print(json.dumps(init_json, indent=2))\n",
    "\n",
    "with open(dataset, 'w') as outfile:\n",
    "    json.dump(init_json, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
