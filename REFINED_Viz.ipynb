{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Prepare expression data from TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['gleason_pattern_primary', 'gleason_pattern_secondary'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e987a17348ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclinical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bcr_patient_uuid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gleason_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'case_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bcr_patient_uuid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aliquot_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gleason_pattern_primary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gleason_pattern_secondary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gleason_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mexpression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['gleason_pattern_primary', 'gleason_pattern_secondary'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def addFile(file): \n",
    "\tdf = pd.read_csv(file, sep = \"\\t\")\n",
    "\tname = os.path.basename(file)\n",
    "\tdf['file_name'] = name\n",
    "\tdf.columns = ['gene', 'fpkm', 'file_name']\n",
    "\treturn(df)\n",
    "\n",
    "def loadExpression(filepath):\n",
    "\tfiles = glob.glob(filepath)     \n",
    "\tdfs = (addFile(f) for f in files)\n",
    "\treturn pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def adjust(x): \n",
    "\treturn x+.0001\n",
    "\n",
    "\n",
    "def topKFeatures(X, y, ifPlot = False, topK = 500):\n",
    "\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k = topK)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    print(\"print 10 best features:\\n\", featureScores.nlargest(10,'Score'))\n",
    "    \n",
    "    if ifPlot == True:\n",
    "        plt.figure()\n",
    "        featureScores.nlargest(10,'Score').plot(kind='barh')\n",
    "        plt.show()\n",
    "    \n",
    "    topk_features = featureScores.nlargest(topK,'Score').Specs.values\n",
    "\n",
    "    return topk_features\n",
    "\n",
    "clinical = pd.read_csv(\"/nfs/home/jaclyns/tcga/nationwidechildrens.org_clinical_patient_prad.txt\", sep=\"\\t\")\n",
    "# print(labels)\n",
    "\n",
    "mapping = pd.read_csv(\"/nfs/home/jaclyns/tcga/prad.txt\", sep=\"\\t\")\n",
    "mapping.columns = [\"case_id\", \"aliquot_id\", \"file_name\"]\n",
    "# print(mapping)\n",
    "\n",
    "expression = loadExpression(\"/nfs/home/jaclyns/tcga/prad/*FPKM-UQ.txt\")\n",
    "# print(expression)\n",
    "\n",
    "labels = clinical[['bcr_patient_uuid', 'gleason_score']].merge(mapping, right_on='case_id', left_on='bcr_patient_uuid')\n",
    "labels = labels[['aliquot_id', 'gleason_pattern_primary', 'gleason_pattern_secondary', 'gleason_score']]\n",
    "\n",
    "expression = expression.merge(mapping, right_on='file_name', left_on='file_name')\n",
    "expression = expression.dropna(subset=['aliquot_id'])\n",
    "matrix = expression.pivot(index = 'aliquot_id', columns = 'gene', values = 'fpkm')\n",
    "fmatrix = matrix.join(labels.set_index('aliquot_id'), on='aliquot_id')\n",
    "\n",
    "preX = fmatrix.drop('gleason_score', 1)\n",
    "prey = fmatrix[['gleason_score']]\n",
    "\n",
    "topfs = topKFeatures(preX,prey, topK=1000)\n",
    "features = preX[topfs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with REFINED\n",
    "\n",
    "In this notebook we show how to convert tabular data into images, and show those images for visualization. As it is explained in the main markdown, REFINED has two steps: Initialization with manifold learning techniques (MDS), and optimization with a search technique (hill climbing). Therefore to perform visualization with REFINED, we need to do the two steps and once we get the coordinate in the square image for each feature of the tabular data we can generate images associate with each datapoint (sample).\n",
    "\n",
    "### 1. In the below cell we perform initialization with MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data  is loaded\n",
      ">>>> MDS dimensionality reduction is done\n",
      ">> Assign features to pixels: 347 / 1000\n",
      ">> Assign features to pixels: 429 / 1000\n",
      ">> Assign features to pixels: 488 / 1000\n",
      ">> Assign features to pixels: 544 / 1000\n",
      ">> Assign features to pixels: 593 / 1000\n",
      ">> Assign features to pixels: 639 / 1000\n",
      ">> Assign features to pixels: 678 / 1000\n",
      ">> Assign features to pixels: 712 / 1000\n",
      ">> Assign features to pixels: 736 / 1000\n",
      ">> Assign features to pixels: 761 / 1000\n",
      ">> Assign features to pixels: 787 / 1000\n",
      ">> Assign features to pixels: 811 / 1000\n",
      ">> Assign features to pixels: 834 / 1000\n",
      ">> Assign features to pixels: 858 / 1000\n",
      ">> Assign features to pixels: 872 / 1000\n",
      ">> Assign features to pixels: 885 / 1000\n",
      ">> Assign features to pixels: 896 / 1000\n",
      ">> Assign features to pixels: 911 / 1000\n",
      ">> Assign features to pixels: 920 / 1000\n",
      ">> Assign features to pixels: 927 / 1000\n",
      ">> Assign features to pixels: 934 / 1000\n",
      ">> Assign features to pixels: 942 / 1000\n",
      ">> Assign features to pixels: 947 / 1000\n",
      ">> Assign features to pixels: 953 / 1000\n",
      ">> Assign features to pixels: 958 / 1000\n",
      ">> Assign features to pixels: 962 / 1000\n",
      ">> Assign features to pixels: 968 / 1000\n",
      ">> Assign features to pixels: 972 / 1000\n",
      ">> Assign features to pixels: 976 / 1000\n",
      ">> Assign features to pixels: 980 / 1000\n",
      ">> Assign features to pixels: 986 / 1000\n",
      ">> Assign features to pixels: 989 / 1000\n",
      ">> Assign features to pixels: 992 / 1000\n",
      ">> Assign features to pixels: 993 / 1000\n",
      ">> Assign features to pixels: 996 / 1000\n",
      ">> Assign features to pixels: 998 / 1000\n",
      ">> Assign features to pixels: 999 / 1000\n",
      ">> Assign features to pixels: 1000 / 1000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import Toolbox\n",
    "from Toolbox import two_d_eq, Assign_features_to_pixels\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import math\n",
    "import os\n",
    "os.chdir('/nfs/home/jaclyns/REFINED/data')\n",
    "#%% Loading the data\n",
    "# empty rows I manually removed from this file\n",
    "# Feat_DF = pd.read_csv(\"normalized_padel_feats_NCI60_672_small.csv\")\n",
    "#Feat_DF = pd.read_csv(\"C:\\\\Users\\\\obazgir\\\\Desktop\\\\CMDS_IMAGES_NEW\\\\normalized_padel_feats_NCI60_672.csv\")\n",
    "Feat_DF = features#.head(10)\n",
    "\n",
    "X = Feat_DF.values; #X = X[:,2:]\n",
    "original_input = pd.DataFrame(data = X)                              # The MDS input should be in a dataframe format with rows as samples and columns as features\n",
    "feature_names_list = original_input.columns.tolist()                 # Extracting feature_names_list (gene_names or descriptor_names)\n",
    "print(\">>>> Data  is loaded\")\n",
    "\n",
    "#%% MDS\n",
    "nn = math.ceil(np.sqrt(len(feature_names_list))) \t\t\t\t     # Image dimension\n",
    "Nn = original_input.shape[1] \t\t\t\t\t\t\t\t\t\t # Number of features\n",
    "    \n",
    "transposed_input = original_input.T \t\t\t\t\t\t\t     # The MDS input data must be transposed , because we want summarize each feature by two values (as compard to regular dimensionality reduction each sample will be described by two values)\n",
    "Euc_Dist = euclidean_distances(transposed_input) \t\t\t\t\t # Euclidean distance\n",
    "Euc_Dist = np.maximum(Euc_Dist, Euc_Dist.transpose())   \t\t\t # Making the Euclidean distance matrix symmetric\n",
    "\n",
    "embedding = MDS(n_components=2)\t\t\t\t\t\t\t\t\t\t # Reduce the dimensionality by MDS into 2 components\n",
    "mds_xy = embedding.fit_transform(transposed_input)\t\t\t\t\t # Apply MDS\t\t\t\n",
    "\n",
    "print(\">>>> MDS dimensionality reduction is done\")\n",
    "\n",
    "eq_xy = two_d_eq(mds_xy,Nn)\n",
    "Img = Assign_features_to_pixels(eq_xy,nn,verbose=1)\t\t\t\t\t# Img is the none-overlapping coordinates generated by MDS\n",
    "\n",
    "#%% To be saved for hill climbing\n",
    "Desc = Feat_DF.columns.tolist();  #Desc = Desc[2:]\t\t\t\t\t# Drug descriptors name\n",
    "Dist = pd.DataFrame(data = Euc_Dist, columns = Desc, index = Desc)\t# Generating a distance matrix which includes the Euclidean distance between each and every descriptor\n",
    "data = (Desc, Dist, Img\t)  \t\t\t\t\t\t\t\t\t\t\t# Preparing the hill climbing inputs\n",
    "\n",
    "# picklename = \"Init_MDS_Euc.pickle\"\n",
    "# picklename = \"Init_PRAD_FPKM.pickle\"\n",
    "# with open(picklename, 'wb') as f:\t\t\t\t\t# The hill climbing input is a pickle, therefore everything is saved as a pickle to be loaded by the hill climbing\n",
    "#     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hill Climbing\n",
    "Once the initializaiton is performed, then we have to apply the search optimizaition (hill climbing). The below bash script will run the search optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpirun -np 32 python3 /nfs/home/jaclyns/REFINED/mpiHill_UF.py --init '/nfs/home/jaclyns/REFINED/data/Init_PRAD_FPKM.pickle'   --mapping 'Mapping_REFINED.pickle'  --evolution \"REFINED_Evolve.csv\" --num 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization\n",
    "Once the search optimization is performed and the coordinates for features are obtained, we can use the coordinates to generate images for visualization purpose or training CNNs. In the below code visualization is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualizing REFFINED images\n",
    "import math\n",
    "import pickle\n",
    "from Toolbox import REFINED_Im_Gen\n",
    "# MDS\n",
    "with open('/nfs/home/jaclyns/glow/Mapping_REFINED.pickle','rb') as file:\n",
    "    gene_names_MDS,coords_MDS,map_in_int_MDS = pickle.load(file)\n",
    "\n",
    "# # We pick the first 100 data points because of computational costs, but you can pick the entire datasets.\n",
    "# # X_REFINED_MDS = REFINED_Im_Gen(X[:100,:],nn, map_in_int_MDS, gene_names_MDS,coords_MDS)\n",
    "X_REFINED_MDS = REFINED_Im_Gen(X,nn, map_in_int_MDS, gene_names_MDS,coords_MDS)\n",
    "\n",
    "# Font = 20\n",
    "samples = Feat_DF.index\n",
    "\n",
    "# aliquot = samples[1]\n",
    "# print(aliquot)\n",
    "# X_REFINED_MDS[0,:]\n",
    "\n",
    "# fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "# plt.imshow(X_REFINED_MDS[1,:].reshape(nn,nn), cmap = 'gray') # cmap = 'viridis')\n",
    "# plt.axis('off')\n",
    "# plt.savefig('/nfs/home/jaclyns/tcga/'+samples[1]+'.png')\n",
    "# plt.close(fig)\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    fig=plt.figure(figsize=(12,8), dpi= 100)\n",
    "    plt.imshow(X_REFINED_MDS[i,:].reshape(nn,nn), cmap = 'gray') #cmap = 'viridis')\n",
    "#     plt.title(\"Example1\", fontsize = Font)\n",
    "    plt.axis('off')\n",
    "    fig.savefig('/nfs/home/jaclyns/tcga/refined_images/'+samples[i]+'.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "# plt.subplot(142)\n",
    "# plt.imshow(X_REFINED_MDS[2,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example2\", fontsize = Font)\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(143)\n",
    "# plt.imshow(X_REFINED_MDS[3,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example3\", fontsize = Font)\n",
    "# plt.axis('off')\n",
    "\n",
    "\n",
    "# plt.subplot(144)\n",
    "# plt.imshow(X_REFINED_MDS[4,:].reshape(26,26), cmap = 'viridis')\n",
    "# plt.title(\"Example4\", fontsize = Font)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to 16bit png\n",
    "Required for Clara Train classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gleason_pattern_primary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gleason_pattern_primary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a4e40988a2ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gleason_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gleason_pattern_primary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gleason_pattern_secondary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/refined/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gleason_pattern_primary'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "labels = prey['gleason_score'].tolist()\n",
    "label1 = prey['gleason_pattern_primary'].tolist()\n",
    "label2 = prey['gleason_pattern_secondary'].tolist()\n",
    "\n",
    "dls = set(labels0)\n",
    "print(dls)\n",
    "dls1 = set(labels1)\n",
    "print(dls1)\n",
    "dls2 = set(labels2)\n",
    "print(dls2)\n",
    "\n",
    "samples = features.index\n",
    "\n",
    "multiToBinary = {6: 0, 7: 1, 8: 2, 9: 3, 10: 4}\n",
    "\n",
    "# clbls = [multiToBinary[x] for x in labels]\n",
    "# values = {0: 0, 1: 0, 2: 0}\n",
    "# for c in clbls:\n",
    "#     values[c] += 1\n",
    "# print(values)\n",
    "\n",
    "training = []\n",
    "for i in range(len(samples)):\n",
    "    iname = \"refined_images/\"+samples[i]+\".png\"\n",
    "    training.append({ \"image\": iname, \"label\": [multiToBinary[labels[i]]] })\n",
    "    \n",
    "init_json = { \"label_format\": [1], \"data_format\": \"channels_last\", \"training\": training }\n",
    "print(json.dumps(init_json, indent=2))\n",
    "# with open('/nfs/home/jaclyns/tcga/dataset.json', 'w') as outfile:\n",
    "#     json.dump(init_json, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
